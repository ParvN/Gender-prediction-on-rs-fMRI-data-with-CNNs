{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all modules required\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "nitorch_dir = \"nitorch/\"\n",
    "sys.path.insert(0, os.path.join(nitorch_dir))\n",
    "from nitorch.metrics import binary_balanced_accuracy, sensitivity, specificity, prepare_values\n",
    "from nitorch.data import *\n",
    "from nitorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from nitorch.trainer import Trainer\n",
    "from nitorch.initialization import weights_init\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "from Code.data import *\n",
    "from Code.models import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read UKB datalabels\n",
    "UKB_label_info = pd.read_excel(\"/Data_labels/UKB_label_info.xlsx\",index_col =None)\n",
    "data_dir = \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "df_trn, df_val  = train_test_split(UKB_label_info,test_size=0.15,stratify=UKB_label_info['Gender'],shuffle=True)\n",
    "df_trn, df_test = train_test_split(df_trn,test_size=0.175,stratify=df_trn['Gender'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_sam = df_trn['Gender'].value_counts().reset_index()\n",
    "df_val_sam = df_val['Gender'].value_counts().reset_index()\n",
    "df_test_sam = df_test['Gender'].value_counts().reset_index()\n",
    "print(df_trn_sam,df_val_sam,df_test_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_val.to_pickle(\"UKB_Val_Data.pkl\")\n",
    "\n",
    "training_set = UKB_FMRI_Dataset_BCNN(data_dir, df_trn)\n",
    "validation_set = UKB_FMRI_Dataset_BCNN(data_dir, df_val)\n",
    "test_set = UKB_FMRI_Dataset_BCNN(data_dir, df_test)\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1}\n",
    "params       = {'batch_size': 1,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1}\n",
    "testparams   = {'batch_size': 1,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0}\n",
    "\n",
    "train_loader = data.DataLoader(training_set, **train_params)\n",
    "val_loader = data.DataLoader(validation_set,**params)\n",
    "test_loader = data.DataLoader(test_set,**testparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model params\n",
    "res_dir = \"/projects/connectome_gender_classification/trial1/UKB/BCNN/\"\n",
    "\n",
    "debug = 1\n",
    "device = 5\n",
    "multi_gpus = None\n",
    "gpu = True\n",
    "num_runs = 3\n",
    "\n",
    "net_name = \"UKB_BCNN\"\n",
    "learn_rate = 0.001\n",
    "weight_decay= 8.4e-07\n",
    "\n",
    "num_epochs = 100\n",
    "images, labels = next(iter(train_loader))\n",
    "input_size = images.shape[1]\n",
    "f_size = images.shape[3]\n",
    "output_size = 1\n",
    "\n",
    "e2e= 16\n",
    "e2n = 128\n",
    "n2g=26\n",
    "\n",
    "dropout = 0.6\n",
    "min_iters = 0\n",
    "mc = ModelCheckpoint(res_dir, \n",
    "        retain_metric=binary_balanced_accuracy,\n",
    "        prepend=\"auto_save_\",\n",
    "        num_iters=-1,\n",
    "        ignore_before=15,\n",
    "        store_best=True,\n",
    "        mode=\"max\")\n",
    "\n",
    "\n",
    "callbacks = [EarlyStopping(patience=10, retain_metric=binary_balanced_accuracy, mode=\"max\", ignore_before=30)]\n",
    "training_callback = None\n",
    "metrics = [binary_balanced_accuracy]\n",
    "\n",
    "on_folder_error_continue = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BCNN(e2e,e2n,n2g,f_size,dropout).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "for i in range(num_runs):\n",
    "    print(\"Starting training for run no: \"+str(i))\n",
    "    del net\n",
    "    net = BCNN(e2e,e2n,n2g,f_size,dropout).cuda(device)\n",
    "    net.eval()\n",
    "    # set hyperparameters\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learn_rate, momentum = 0.9, weight_decay=weight_decay)\n",
    "    net_name = str(\"UKB_BCNN\") + str(\"_model_\")+ str(i)\n",
    "\n",
    "    # define the Trainer\n",
    "    trainer = Trainer(\n",
    "        net,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        metrics=metrics,\n",
    "        callbacks=callbacks,\n",
    "        training_time_callback=training_callback,\n",
    "        prediction_type=\"classification\",\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # run training\n",
    "    net, report = trainer.train_model(\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        show_train_steps=100,\n",
    "        show_validation_epochs=1, # show validation loss every epoch\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    torch.save(net.state_dict(), (res_dir + net_name))\n",
    "\n",
    "    # visualize training result\n",
    "    trainer.visualize_training(report, save_fig_path = res_dir)\n",
    "    val_acc.append(report['best_metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.imread(res_dir + str(\"_binary_balanced_accuracy.png\"))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = plt.imread(res_dir + str(\"_loss.png\"))\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "net = BCNN(e2e,e2n,n2g,f_size,dropout).cuda(device)\n",
    "acrcy = []\n",
    "sntvty = []\n",
    "sptvty = []\n",
    "for num in range(num_runs):\n",
    "    net_name = str(\"UKB_BCNN\") + str(\"_model_\")+ str(num)\n",
    "    net.load_state_dict(torch.load(res_dir+net_name)) \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    class_threshold = 0.5\n",
    "    net.eval() \n",
    "    for i,data in enumerate(test_loader): \n",
    "        X,y = data \n",
    "        X, y = Variable(X.cuda(device)), Variable(y.cuda(device))\n",
    "        output = net.forward(X)        \n",
    "        #pred = torch.tensor(1 if (F.sigmoid(output) >= class_threshold) else 0)\n",
    "        pred = torch.argmax(F.softmax(output, dim=1))\n",
    "        all_preds.append(pred.cpu().numpy().item())\n",
    "        all_labels.append(y.cpu().numpy().item())\n",
    "\n",
    "    acrcy.append(binary_balanced_accuracy(all_labels, all_preds))\n",
    "    sntvty.append(sensitivity(all_labels, all_preds))\n",
    "    sptvty.append(specificity(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/jrieke/cnn-interpretability\n",
    "def sensitivity_analysis(model, image_tensor, target_class=None, postprocess='abs', apply_softmax=True, cuda=True,\n",
    "                         verbose=False):\n",
    "    \"\"\"\n",
    "    Perform sensitivity analysis (via backpropagation; Simonyan et al. 2014) to\n",
    "    determine the relevance of each image pixel\n",
    "    for the classification decision. Return a relevance heatmap over the input image.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The pytorch model. Should be set to eval mode.\n",
    "        image_tensor (torch.Tensor or numpy.ndarray): The image to run through the `model` (channels first!).\n",
    "        target_class (int): The target output class for which to produce the heatmap.\n",
    "                      If `None` (default), use the most likely class from the `model`s output.\n",
    "        postprocess (None or 'abs' or 'square'): The method to postprocess the heatmap with. `'abs'` is used\n",
    "                                                 in Simonyan et al. 2014, `'square'` is used in Montavon et al. 2018.\n",
    "        apply_softmax (boolean): Whether to apply the softmax function to the output. Useful for models that are trained\n",
    "                                 with `torch.nn.CrossEntropyLoss` and do not apply softmax themselves.\n",
    "        appl (None or 'binary' or 'categorical'): Whether the output format of the `model` is binary\n",
    "                                                         (i.e. one output neuron with sigmoid activation) or categorical\n",
    "                                                         (i.e. multiple output neurons with softmax activation).\n",
    "                                                         If `None` (default), infer from the shape of the output.\n",
    "        cuda (boolean): Whether to run the computation on a cuda device.\n",
    "        verbose (boolean): Whether to display additional output during the computation.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of the same shape as image_tensor, indicating the relevance of each image pixel.\n",
    "    \"\"\"\n",
    "    if postprocess not in [None, 'abs', 'square']:\n",
    "        raise ValueError(\"postprocess must be None, 'abs' or 'square'\")\n",
    "\n",
    "    # Forward pass.\n",
    "    \n",
    "    X = Variable(image_tensor, requires_grad=True)  # add dimension to simulate batch\n",
    "    output = model(X)\n",
    "    if apply_softmax:\n",
    "        output = F.softmax(output)\n",
    "\n",
    "    # Backward pass.\n",
    "    model.zero_grad()\n",
    "    output_class = output.max(1)[1].data[0]\n",
    "    if verbose: print('Image was classified as', output_class, 'with probability', output.max(1)[0].data[0])\n",
    "    one_hot_output = torch.zeros(output.size())\n",
    "    if target_class is None:\n",
    "        one_hot_output[0, output_class] = 1\n",
    "    else:\n",
    "        one_hot_output[0, target_class] = 1\n",
    "    if cuda:\n",
    "        one_hot_output = one_hot_output.cuda(image_tensor.get_device())\n",
    "    output.backward(gradient=one_hot_output)\n",
    "\n",
    "    relevance_map = X.grad.data[0].cpu().numpy()\n",
    "    \n",
    "\n",
    "    # Postprocess the relevance map.\n",
    "    if postprocess == 'abs':  # as in Simonyan et al. (2014)\n",
    "        return np.abs(relevance_map)\n",
    "    elif postprocess == 'square':  # as in Montavon et al. (2018)\n",
    "        return relevance_map ** 2\n",
    "    elif postprocess is None:\n",
    "        return relevance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BCNN(e2e,e2n,n2g,f_size,dropout).cuda(device)\n",
    "net_name = str(\"UKB_BCNN\") + str(\"_model_\")+ str(0)\n",
    "net.load_state_dict(torch.load(res_dir+net_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "relevance_map_backprop = []\n",
    "clas = []\n",
    "for i,(image,label) in enumerate(test_loader):\n",
    "        \n",
    "        clas.append(label)\n",
    "        \n",
    "        image = Variable(image).cuda(device)\n",
    "        label = Variable(label).cuda(device)   \n",
    "        relevance_map_backprop.append(sensitivity_analysis(net,image,target_class=label,postprocess=None,cuda=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_connectome \n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "\n",
    "img = nib.load('/Visualization/test_file.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_connectome =  plotting.find_probabilistic_atlas_cut_coords(maps_img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognize between men and women\n",
    "mat = np.asarray(relevance_map_backprop)\n",
    "labels = torch.stack(clas).cpu().numpy()\n",
    "\n",
    "male_avg = []\n",
    "female_avg = []\n",
    "\n",
    "for i,val in enumerate(labels):\n",
    "    if val[0] ==0:\n",
    "        female_avg.append(mat[i][0])\n",
    "        \n",
    "    else:\n",
    "        male_avg.append(mat[i][0])\n",
    "                \n",
    "\n",
    "m_avg = np.average(np.asarray(male_avg),axis=0)\n",
    "f_avg = np.average(np.asarray(female_avg),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_connectome(f_avg+f_avg.T,coords_connectome,title='Female Activation Connectome - UK Biobank',edge_threshold='99.5%',colorbar= True,node_size=6)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_connectome(m_avg+m_avg.T,coords_connectome,title='Male Activation Connectome - UK Biobank',edge_threshold='99.5%',colorbar= True,node_size=6)\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
